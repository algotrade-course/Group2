{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample Backtest\n",
    "\n",
    "This notebook runs a reproducible out-of-sample backtest using the reference optimized parameters. It compares the performance of the optimized parameters against the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.optimization.config_loader import ConfigLoader\n",
    "from src.pipeline import TradingPipeline\n",
    "from src.backtest.performance import PerformanceMetrics\n",
    "from src.visualization.comparison import plot_parameter_comparison, plot_equity_curves_comparison\n",
    "from src.visualization.backtest import plot_backtest_results, plot_equity_curve, plot_trade_analysis\n",
    "\n",
    "RESULTS_DIR = os.path.join('..', 'results', 'outsample')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Out-of-Sample Period and Parameter Source\n",
    "\n",
    "Set the start and end dates for the out-of-sample testing period and choose which optimized parameters to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_date = '2024-06-01'\n",
    "test_end_date = '2025-01-01'\n",
    "\n",
    "# Choose whether to use reference parameters (True) or custom optimized parameters (False)\n",
    "use_reference_parameters = True\n",
    "\n",
    "print(f\"Out-of-sample testing period: {test_start_date} to {test_end_date}\")\n",
    "print(f\"Using {'reference' if use_reference_parameters else 'custom'} optimized parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configurations\n",
    "\n",
    "Load both the default configuration and the optimized parameters from config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_loader = ConfigLoader()\n",
    "default_config = config_loader.get_config()\n",
    "\n",
    "\n",
    "if use_reference_parameters:\n",
    "    optimized_config_path = os.path.join('..', 'config', 'reference_optimized_parameters.json')\n",
    "    if not os.path.exists(optimized_config_path):\n",
    "        print(f\"Reference optimized parameters file not found at {optimized_config_path}\")\n",
    "        print(\"Using latest optimized parameters instead.\")\n",
    "        optimized_config_path = os.path.join('..', 'config', 'optimized_parameters.json')\n",
    "else:\n",
    "    optimized_config_path = os.path.join('..', 'config', 'optimized_parameters.json')\n",
    "\n",
    "with open(optimized_config_path, 'r') as f:\n",
    "    optimized_config = json.load(f)\n",
    "\n",
    "optimized_params = optimized_config['parameters']\n",
    "\n",
    "print(f\"Loading optimized parameters from: {optimized_config_path}\")\n",
    "print(\"\\nOptimized Parameters:\")\n",
    "for param, value in optimized_params.items():\n",
    "    if param not in ['trailing_trigger', 'trailing_atr', 'trading_start', 'trading_end', 'market_close_time']:\n",
    "        print(f\"- {param}: {value}\")\n",
    "\n",
    "print(\"\\nDefault Parameters:\")\n",
    "default_params = default_config['parameters']\n",
    "for param, value in default_params.items():\n",
    "    if param not in ['trailing_trigger', 'trailing_atr', 'trading_start', 'trading_end', 'market_close_time']:\n",
    "        print(f\"- {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Backtest with Optimized Parameters\n",
    "\n",
    "Execute the backtest using the optimized parameters on the out-of-sample period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running backtest with optimized parameters...\")\n",
    "\n",
    "temp_optimized_config = default_config.copy()\n",
    "temp_optimized_config['parameters'] = optimized_params\n",
    "\n",
    "optimized_pipeline = TradingPipeline(temp_optimized_config)\n",
    "\n",
    "optimized_timeframe = optimized_params.get('default_timeframe', '15min')\n",
    "\n",
    "optimized_results, optimized_signals_df = optimized_pipeline.run_backtest(\n",
    "    test_start_date, test_end_date, optimized_timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimized_results and 'trades' in optimized_results and not optimized_results['trades'].empty:\n",
    "    optimized_performance = PerformanceMetrics(\n",
    "        optimized_results['trades'],\n",
    "        optimized_results['portfolio_history'],\n",
    "        risk_free_rate=default_config.get('backtest', {}).get('risk_free_rate', 0.03)\n",
    "    )\n",
    "    optimized_metrics = optimized_performance.generate_report()\n",
    "    \n",
    "    print(\"Performance with Optimized Parameters:\")\n",
    "    for metric, value in optimized_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\" if isinstance(value, (int, float)) else f\"{metric}: {value}\")\n",
    "else:\n",
    "    optimized_metrics = None\n",
    "    print(\"No trades were executed with optimized parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Optimized Results\n",
    "\n",
    "Generate charts and visualizations of the backtest results with optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimized_results and 'trades' in optimized_results and not optimized_results['trades'].empty:\n",
    "    fig = plot_backtest_results(\n",
    "        optimized_signals_df,\n",
    "        trades_df=optimized_results['trades'],\n",
    "        save_path=os.path.join(RESULTS_DIR, 'optimized_backtest_chart.png')\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No visualization available - no trades were executed with optimized parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimized_results and 'portfolio_history' in optimized_results and len(optimized_results['portfolio_history']) > 1:\n",
    "    fig = plot_equity_curve(\n",
    "        optimized_results['portfolio_history'],\n",
    "        save_path=os.path.join(RESULTS_DIR, 'optimized_equity_curve.png')\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No equity curve available - insufficient data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimized_results and 'trades' in optimized_results and not optimized_results['trades'].empty:\n",
    "    fig_trades, fig_exit, profit_by_exit = plot_trade_analysis(\n",
    "        optimized_results['trades'],\n",
    "        save_path=os.path.join(RESULTS_DIR, 'optimized_trade_analysis')\n",
    "    )\n",
    "    \n",
    "    if fig_trades:\n",
    "        plt.figure(fig_trades.number)\n",
    "        plt.show()\n",
    "    \n",
    "    if fig_exit:\n",
    "        plt.figure(fig_exit.number)\n",
    "        plt.show()\n",
    "    \n",
    "    if profit_by_exit is not None:\n",
    "        print(\"\\nProfit by Exit Reason:\")\n",
    "        display(profit_by_exit)\n",
    "else:\n",
    "    print(\"No trade analysis available - no trades were executed with optimized parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Backtest with Default Parameters\n",
    "\n",
    "Execute the backtest using the default parameters on the out-of-sample period for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running backtest with default parameters for comparison...\")\n",
    "\n",
    "default_pipeline = TradingPipeline(default_config)\n",
    "default_timeframe = default_params.get('default_timeframe', '15min')\n",
    "\n",
    "default_results, default_signals_df = default_pipeline.run_backtest(\n",
    "    test_start_date, test_end_date, default_timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_results and 'trades' in default_results and not default_results['trades'].empty:\n",
    "    default_performance = PerformanceMetrics(\n",
    "        default_results['trades'],\n",
    "        default_results['portfolio_history'],\n",
    "        risk_free_rate=default_config.get('backtest', {}).get('risk_free_rate', 0.03)\n",
    "    )\n",
    "    default_metrics = default_performance.generate_report()\n",
    "    \n",
    "    print(\"Performance with Default Parameters:\")\n",
    "    for metric, value in default_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\" if isinstance(value, (int, float)) else f\"{metric}: {value}\")\n",
    "    \n",
    "    fig = plot_equity_curve(\n",
    "        default_results['portfolio_history'],\n",
    "        save_path=os.path.join(RESULTS_DIR, 'default_equity_curve.png')\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    default_metrics = None\n",
    "    print(\"No trades were executed with default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Default vs Optimized Parameters\n",
    "\n",
    "Generate comparison visualizations to show the difference in performance between the default and optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_metrics and optimized_metrics:\n",
    "    print(\"Generating comparison visualizations...\")\n",
    "    \n",
    "    fig_comparison, comparison_df = plot_parameter_comparison(\n",
    "        default_metrics, \n",
    "        optimized_metrics, \n",
    "        save_path=os.path.join(RESULTS_DIR, 'metrics_comparison.png')\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nComparison of Default vs Optimized Parameters:\")\n",
    "    display(comparison_df)\n",
    "    comparison_df.to_csv(os.path.join(RESULTS_DIR, 'parameter_comparison.csv'))\n",
    "else:\n",
    "    print(\"Cannot compare metrics - insufficient data\")\n",
    "\n",
    "if default_metrics and optimized_metrics and 'portfolio_history' in default_results and 'portfolio_history' in optimized_results:\n",
    "    fig_curves = plot_equity_curves_comparison(\n",
    "        default_results['portfolio_history'],\n",
    "        optimized_results['portfolio_history'],\n",
    "        save_path=os.path.join(RESULTS_DIR, 'default_vs_optimized.png')\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot compare equity curves - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results\n",
    "\n",
    "Save the out-of-sample backtest results to a JSON file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimized_metrics:\n",
    "    result_data = {\n",
    "        \"test_period\": {\n",
    "            \"start_date\": test_start_date,\n",
    "            \"end_date\": test_end_date\n",
    "        },\n",
    "        \"optimized_source\": \"reference\" if use_reference_parameters else \"custom\",\n",
    "        \"optimized_parameters\": optimized_params,\n",
    "        \"optimized_metrics\": {\n",
    "            k: float(v) if isinstance(v, (int, float, np.number)) else v for k, v in optimized_metrics.items()\n",
    "        },\n",
    "        \"default_metrics\": {\n",
    "            k: float(v) if isinstance(v, (int, float, np.number)) else v for k, v in default_metrics.items()\n",
    "        } if default_metrics else None,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(RESULTS_DIR, 'outsample_backtest_results.json'), 'w') as f:\n",
    "        json.dump(result_data, f, indent=4)\n",
    "    \n",
    "    print(f\"Out-of-sample backtest results saved to {RESULTS_DIR}/outsample_backtest_results.json\")\n",
    "else:\n",
    "    print(\"No results saved - insufficient data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
